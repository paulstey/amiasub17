
\documentclass[10pt]{article}

\usepackage{cite}
\usepackage{amsmath}
\usepackage[numbers]{natbib}
\usepackage[margin=1.75in]{geometry}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\renewcommand{\baselinestretch}{1.2}


\title{\fontsize{14}{14} Predicting Rare Adverse Events with Modified Stochastic AdaBoost}
\author{}
\date{}

\setlength{\parindent}{0em}
\setlength{\parskip}{1.2em}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother


\begin{document}




\maketitle

\begin{abstract}
The problem of predicting rare events is one that emerges frequently in biomedical and health informatics. In the context of classification problems, the prediction of rare events relies on the ability to handle severe class imbalance in the dependent variable. The current project explores a number approaches for handling severe class imbalance. In particular, several Monte Carlo studies using simulated data investigate the relative merits of three approaches for handling class imbalance; the first relies on the well-known SMOTE pre-processing algorithm \cite{chawla02}, the second uses an over-sampling procedure as part of the bagging procedure stochastic boosting, the third is a modified version of stochastic AdaBoost that incorporates both an over-sampling step as well as cost-sensitive learning. Finally, these three methods are explore in a real-data example predicting adverse events resulting from drug interactions involving plant compounds. 
\end{abstract}

\section{Background}

Class imbalance in prediction problems is exceedingly common across many disciplines. The field of biomedical informatics represents a particularly striking example, given how frequently researchers are faced with the challenge of predicting rare events. 

In this paper, the phrase ``class imbalance'' references the phenomenon in which the dependent variable in a data set is categorical and at least one of the categories is under-represented. For instance, consider the case of building a model that predicts the underlying condition of patients visiting the emergency room. Suppose there are training data consisting of 100,000 health records containing information such as previous emergency room visits, family medical histories, \textit{et cetera}. Also suppose that this training data has the patients' eventual diagnoses included. For example, consider the case of Long QT Syndrome (LQTS), a condition with a prevalence close to 1:2000 \cite{schwartz09}. It would be expected that LQTS manifest in about 50 patients in the training data. If one were to use these training data to build a classification model that predicts future patients' diagnoses, one would likely find the fitted model has great difficultly predicting LQTS---the model simply has not seen enough example of LQTS to accurately predict the disorder. 

The problem of class imbalance in supervised learning has been studied frequently (e.g., XXXX, XXXX, XXXX). And while there has been considerable progress, a general method for handling the most severe cases of class imbalance remains elusive. Many of the existing methods have been primarily used in cases of imbalanced data where the minority class might be 20\% or 30\% of the sample (e.g., XXXX, XXXX). However in the biomedical field a ``rare'' case might be one that presents 5\% or 1\% of the time or less. And in these cases of \textit{severe} class imbalance, there remains considerable potential for improvement. 


\subsection{Methods for Handling Class Imbalance}
This paper consider two major categories of approaches for handling sever class imbalance. The first is sampling-based, and attempts to correct the imbalance through some form of over- or under-sampling. This approach has the obvious advantage that the degree of over- or under-sampling can be finely tuned to the desired level of the researcher. The second category of approaches is a species of cost-sensitive learning; these are methods that preferentially weight the minority class cases in the model fitting process. That is, the model's loss function more severely penalizes the misclassification of majority-class cases. Example from both categories of methods are examined in this paper.

\subsubsection{SMOTE}



\subsection{Boosting}
Boosting methods have a long history, and they have proven to be some of the most effective model-fitting methods for supervised learning problems. Boosting falls in to the category of ensemble methods; the essential feature of ensemble methods is the aggregation of many different models in to a single overall model for classification or regression. In the case of boosting for classification problems, the basic idea is that many ``weak'' classifiers are combined to form one ``committee'' \cite{hastie09}. This simple idea has proven to be extremely powerful. Moreover, the boosting framework is incredibly flexible in that the classifiers to be aggregated can be selected from any number of common modeling approaches---trees have proven especially productive.

AdaBoost (XXXX) is typically considered to be the first boosting-type algorithm for classification. The concept underlying AdaBoost is quite elegant. The AdaBoost model fitting process begins by assigning each observation equal weights. In a general sense, these weights represent how severely the loss function penalizes misclassification of a given observation. The algorithm then iterates through several ``rounds''. At each round, a single decision tree with a depth of one is fitted, then before proceeding to the next round the algorithm updates the weights for each observation according to whether or not the observation was correctly classified or not in the current round. This has the effect of generating a model fitting procedure in which the algorithm ``tries harder'' to correctly classify those observations that were previously misclassified. Algorithm 1 below provides a more detailed explication of AdaBoost.

 
%\begin{algorithm}
   % \SetKwInOut{Input}{Input}
    %\SetKwInOut{Output}{Output}

%    \underline{function Euclid} $(a,b)$\;
  %  \Input{Two nonnegative integers $a$ and $b$}
    %\Output{$\gcd(a,b)$}
    %\eIf{$b=0$}
      %{
        %return $a$\;
      %}
      %{
        %return Euclid$(b,a\mod b)$\;
      %}
    %\caption{Euclid's algorithm for finding the greatest common divisor of two nonnegative integers}
%\end{algorithm}



\begin{algorithm}
\caption{AdaBoost}\label{adaboost}
\begin{algorithmic}[1]
	\Procedure{adaboost}{}

		\State Initialize weights, $w_i = 1/N$ for $i = 1, 2, ... N$
		\For{$t = 1...T$}
			\State Fit classifier $h_t(x)$ to training data using weights $w_i$
			\State Compute error: 
				\State $$\epsilon_t = \frac{\sum_{i=1}^{N} w_i \cdot I(y_i \ne h_t(x_i))}{\sum_{i = 1}^{N} w_i}$$
			\State Compute $\alpha_t$:
				\State $$\alpha_t = \frac{1}{2} \text{log} \left(\frac{1 - \epsilon_t}{\epsilon_t} \right)$$
			\State Update weights for next round:
				\State \[ w_i \gets w_i \cdot \left\{ \begin{array}{lr}
				                                                        e^{-\alpha_t} & : h_t(x_i) = y_i \\
				                                                        e^{\alpha_t} & : h_t(x_i) \ne y_i \\
				                                                      \end{array}
				                                            \right.
				          \]
		\EndFor
	\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{Methods}

\section{Results}

\section{Conclusion}


\newpage 

\bibliography{refs}
\bibliographystyle{unsrtnat}

\end{document}